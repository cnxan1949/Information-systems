{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数初始化\n",
    "def gaussian_weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # 字符串查找find，找不到返回-1，不等-1即字符串中含有该字符\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.04)\n",
    "\n",
    "\n",
    "# 验证模型在验证集上的正确率\n",
    "def validate(model, dataset, batch_size):\n",
    "    val_loader = data.DataLoader(dataset, batch_size)\n",
    "    result, num = 0.0, 0\n",
    "    for images, labels in val_loader:\n",
    "        pred = model.forward(images)\n",
    "        pred = np.argmax(pred.data.numpy(), axis=1)\n",
    "        labels = labels.data.numpy()\n",
    "        result += np.sum((pred == labels))\n",
    "        num += len(images)\n",
    "    acc = result / num\n",
    "    return acc\n",
    "\n",
    "# 我们通过继承Dataset类来创建我们自己的数据加载类，命名为FaceDataset\n",
    "class FaceDataset(data.Dataset):\n",
    "\n",
    "    # 初始化\n",
    "    def __init__(self, root):\n",
    "        super(FaceDataset, self).__init__()\n",
    "        self.root = root\n",
    "        df_path = pd.read_csv(root + '\\\\image_emotion.csv', header=None, usecols=[0])\n",
    "        df_label = pd.read_csv(root + '\\\\image_emotion.csv', header=None, usecols=[1])\n",
    "        self.path = np.array(df_path)[:, 0]\n",
    "        self.label = np.array(df_label)[:, 0]\n",
    "\n",
    "    \n",
    "    # 读取某幅图片，item为索引号\n",
    "    def __getitem__(self, item):\n",
    "        face = cv2.imread(self.root + '\\\\' + self.path[item])\n",
    "        # 读取单通道灰度图\n",
    "        face_gray = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        # 高斯模糊\n",
    "        # face_Gus = cv2.GaussianBlur(face_gray, (3,3), 0)\n",
    "        # 直方图均衡化\n",
    "        face_hist = cv2.equalizeHist(face_gray)\n",
    "        # 像素值标准化\n",
    "        face_normalized = face_hist.reshape(1, 48, 48) / 255.0 # 为与pytorch中卷积神经网络API的设计相适配，需reshape原图\n",
    "        # 用于训练的数据需为tensor类型\n",
    "        face_tensor = torch.from_numpy(face_normalized) # 将python中的numpy数据类型转化为pytorch中的tensor数据类型\n",
    "        face_tensor = face_tensor.type('torch.FloatTensor') # 指定为'torch.FloatTensor'型，否则送进模型后会因数据类型不匹配而报错\n",
    "        label = self.label[item]\n",
    "        return face_tensor, label\n",
    "\n",
    "\n",
    "    # 获取数据集样本个数\n",
    "    def __len__(self):\n",
    "        return self.path.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceCNN(nn.Module):\n",
    "    # 初始化网络结构\n",
    "    def __init__(self):\n",
    "        super(FaceCNN, self).__init__()\n",
    "\n",
    "        # 第一次卷积、池化\n",
    "        # Одна свертка, объединение\n",
    "\n",
    " \n",
    " \n",
    "        self.conv1 = nn.Sequential(\n",
    "            # 输入通道数in_channels，输出通道数(即卷积核的通道数)out_channels，卷积核大小kernel_size，步长stride，对称填0行列数padding\n",
    "            # input:(bitch_size, 1, 48, 48), output:(bitch_size, 64, 48, 48), (48-3+2*1)/1+1 = 48\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1), # 卷积层\n",
    "            nn.BatchNorm2d(num_features=64), # 归一化\n",
    "            nn.RReLU(inplace=True), # 激活函数\n",
    "            # output(bitch_size, 64, 24, 24)\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 最大值池化\n",
    "        )\n",
    "\n",
    "        # 第二次卷积、池化\n",
    "        # 2 свертка, объединение\n",
    "        self.conv2 = nn.Sequential(\n",
    "            # input:(bitch_size, 64, 24, 24), output:(bitch_size, 128, 24, 24), (24-3+2*1)/1+1 = 24\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.RReLU(inplace=True),\n",
    "            # output:(bitch_size, 128, 12 ,12)\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # 第三次卷积、池化\n",
    "        # # 3 свертка, объединение\n",
    "        self.conv3 = nn.Sequential(\n",
    "            # input:(bitch_size, 128, 12, 12), output:(bitch_size, 256, 12, 12), (12-3+2*1)/1+1 = 12\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.RReLU(inplace=True),\n",
    "            # output:(bitch_size, 256, 6 ,6)\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # 参数初始化\n",
    "        self.conv1.apply(gaussian_weights_init)\n",
    "        self.conv2.apply(gaussian_weights_init)\n",
    "        self.conv3.apply(gaussian_weights_init)\n",
    "\n",
    "        # 全连接层\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=256*6*6, out_features=4096),\n",
    "            nn.RReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=4096, out_features=1024),\n",
    "            nn.RReLU(inplace=True),\n",
    "            nn.Linear(in_features=1024, out_features=256),\n",
    "            nn.RReLU(inplace=True),\n",
    "            nn.Linear(in_features=256, out_features=7),\n",
    "        )\n",
    "\n",
    "    # 前向传播\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        # 数据扁平化\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        y = self.fc(x)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataset, val_dataset, batch_size, epochs, learning_rate, wt_decay):\n",
    "    # 载入数据并分割batch\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size)\n",
    "    # 构建模型\n",
    "    model = FaceCNN()\n",
    "    # 损失函数\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    # 优化器\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=wt_decay)\n",
    "    # 学习率衰减\n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.8)\n",
    "    # 逐轮训练\n",
    "    for epoch in range(epochs):\n",
    "        # 记录损失值\n",
    "        loss_rate = 0\n",
    "        # scheduler.step() # 学习率衰减\n",
    "        model.train() # 模型训练\n",
    "        for images, emotion in train_loader:\n",
    "            # 梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            # 前向传播\n",
    "            output = model.forward(images)\n",
    "            # 误差计算\n",
    "            loss_rate = loss_function(output, emotion)\n",
    "            # 误差的反向传播\n",
    "            loss_rate.backward()\n",
    "            # 更新参数\n",
    "            optimizer.step()\n",
    "\n",
    "        # 打印每轮的损失\n",
    "        print('After {} epochs , the loss_rate is : '.format(epoch+1), loss_rate.item())\n",
    "        if epoch % 5 == 0:\n",
    "            model.eval() # 模型评估\n",
    "            acc_train = validate(model, train_dataset, batch_size)\n",
    "            acc_val = validate(model, val_dataset, batch_size)\n",
    "            print('After {} epochs , the acc_train is : '.format(epoch+1), acc_train)\n",
    "            print('After {} epochs , the acc_val is : '.format(epoch+1), acc_val)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1 epochs , the loss_rate is :  1.6478160619735718\n",
      "After 1 epochs , the acc_train is :  0.33325\n",
      "After 1 epochs , the acc_val is :  0.3351029942662986\n",
      "After 2 epochs , the loss_rate is :  1.3605015277862549\n",
      "After 3 epochs , the loss_rate is :  1.1992241144180298\n",
      "After 4 epochs , the loss_rate is :  1.11577570438385\n",
      "After 5 epochs , the loss_rate is :  0.9995365142822266\n",
      "After 6 epochs , the loss_rate is :  0.9722229838371277\n",
      "After 6 epochs , the acc_train is :  0.498375\n",
      "After 6 epochs , the acc_val is :  0.485028668507114\n",
      "After 7 epochs , the loss_rate is :  0.9511452317237854\n",
      "After 8 epochs , the loss_rate is :  0.9188267588615417\n",
      "After 9 epochs , the loss_rate is :  0.8031433820724487\n",
      "After 10 epochs , the loss_rate is :  0.8001483678817749\n",
      "After 11 epochs , the loss_rate is :  0.764254093170166\n",
      "After 11 epochs , the acc_train is :  0.49795833333333334\n",
      "After 11 epochs , the acc_val is :  0.462730940751752\n",
      "After 12 epochs , the loss_rate is :  0.7075379490852356\n",
      "After 13 epochs , the loss_rate is :  0.633902907371521\n",
      "After 14 epochs , the loss_rate is :  0.7548090815544128\n",
      "After 15 epochs , the loss_rate is :  0.6096470355987549\n",
      "After 16 epochs , the loss_rate is :  0.6574088931083679\n",
      "After 16 epochs , the acc_train is :  0.4802916666666667\n",
      "After 16 epochs , the acc_val is :  0.4402208536844341\n",
      "After 17 epochs , the loss_rate is :  0.5642593502998352\n",
      "After 18 epochs , the loss_rate is :  0.5490223169326782\n",
      "After 19 epochs , the loss_rate is :  0.529041051864624\n",
      "After 20 epochs , the loss_rate is :  0.4570006728172302\n",
      "After 21 epochs , the loss_rate is :  0.37036365270614624\n",
      "After 21 epochs , the acc_train is :  0.69675\n",
      "After 21 epochs , the acc_val is :  0.5495858993416861\n",
      "After 22 epochs , the loss_rate is :  0.3553721606731415\n",
      "After 23 epochs , the loss_rate is :  0.4203334152698517\n",
      "After 24 epochs , the loss_rate is :  0.37740013003349304\n",
      "After 25 epochs , the loss_rate is :  0.20521265268325806\n",
      "After 26 epochs , the loss_rate is :  0.19144250452518463\n",
      "After 26 epochs , the acc_train is :  0.8455833333333334\n",
      "After 26 epochs , the acc_val is :  0.5829263113187513\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(model, model_save_path)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 15\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m FaceDataset(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./face_images/verify_set\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 超参数可自行指定\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwt_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 保存模型\u001b[39;00m\n\u001b[0;32m      8\u001b[0m model_save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./model/model_cnn.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[1;32mIn[4], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_dataset, val_dataset, batch_size, epochs, learning_rate, wt_decay)\u001b[0m\n\u001b[0;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# 前向传播\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# 误差计算\u001b[39;00m\n\u001b[0;32m     24\u001b[0m loss_rate \u001b[38;5;241m=\u001b[39m loss_function(output, emotion)\n",
      "Cell \u001b[1;32mIn[3], line 57\u001b[0m, in \u001b[0;36mFaceCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 57\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)\n\u001b[0;32m     59\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x)\n",
      "File \u001b[1;32md:\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32md:\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\pooling.py:166\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_jit_internal.py:484\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_false(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:782\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[1;32m--> 782\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # 数据集实例化(创建数据集)\n",
    "    train_dataset = FaceDataset(root='./face_images/train_set')\n",
    "    val_dataset = FaceDataset(root='./face_images/verify_set')\n",
    "    # 超参数可自行指定\n",
    "    model = train(train_dataset, val_dataset, batch_size=128, epochs=100, learning_rate=0.1, wt_decay=0)\n",
    "    # 保存模型\n",
    "    model_save_path = './model/model_cnn.pkl'\n",
    "    if not os.path.exists(os.path.dirname(model_save_path)):\n",
    "        os.makedirs(os.path.dirname(model_save_path))\n",
    "    torch.save(model, model_save_path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
