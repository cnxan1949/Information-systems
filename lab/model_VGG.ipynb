{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "LR = 0.01\n",
    "EPOCH = 60\n",
    "DEVICE = torch.device('cuda')\n",
    "\n",
    "path_train = './face_images/vgg_train_set'\n",
    "path_vaild = './face_images/vgg_verify_set'\n",
    "\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.Grayscale(),#使用ImageFolder默认扩展为三通道，重新变回去就行\n",
    "    transforms.RandomHorizontalFlip(),#随机翻转\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5),#随机调整亮度和对比度\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "transforms_vaild = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "data_train = torchvision.datasets.ImageFolder(root=path_train,transform=transforms_train)\n",
    "data_vaild = torchvision.datasets.ImageFolder(root=path_vaild,transform=transforms_vaild)\n",
    "\n",
    "train_set = torch.utils.data.DataLoader(dataset=data_train,batch_size=BATCH_SIZE,shuffle=True)\n",
    "vaild_set = torch.utils.data.DataLoader(dataset=data_vaild,batch_size=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(VGG, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0],-1)\n",
    "\n",
    "\n",
    "def vgg_block(num_convs, in_channels, out_channels):\n",
    "    blk = []\n",
    "    for i in range(num_convs):\n",
    "        if i == 0:\n",
    "            blk.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        else:\n",
    "            blk.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        blk.append(nn.ReLU())\n",
    "    blk.append(nn.MaxPool2d(kernel_size=2, stride=2)) # 这里会使宽高减半\n",
    "    return nn.Sequential(*blk)\n",
    "    \n",
    "    \n",
    "conv_arch = ((2, 1, 32), (3, 32, 64), (3, 64, 128))\n",
    "# 经过5个vgg_block, 宽高会减半5次, 变成 224/32 = 7\n",
    "fc_features = 128 * 6* 6 # c * w * h\n",
    "fc_hidden_units = 4096 # 任意\n",
    "\n",
    "def vgg(conv_arch, fc_features, fc_hidden_units):\n",
    "    net = nn.Sequential()\n",
    "    # 卷积层部分\n",
    "    for i, (num_convs, in_channels, out_channels) in enumerate(conv_arch):\n",
    "        # 每经过一个vgg_block都会使宽高减半\n",
    "        net.add_module(\"vgg_block_\" + str(i+1), vgg_block(num_convs, in_channels, out_channels))\n",
    "    # 全连接层部分\n",
    "    net.add_module(\"fc\", nn.Sequential(\n",
    "                                 VGG(),\n",
    "                                 nn.Linear(fc_features, fc_hidden_units),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.5),\n",
    "                                 nn.Linear(fc_hidden_units, fc_hidden_units),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.5),\n",
    "                                 nn.Linear(fc_hidden_units, 7)\n",
    "                                ))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg(conv_arch, fc_features, fc_hidden_units)\n",
    "model.to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(),lr=LR,momentum=0.9)\n",
    "            #optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_loss = []\n",
    "train_ac = []\n",
    "vaild_loss = []\n",
    "vaild_ac = []\n",
    "y_pred = []\n",
    "\n",
    "def train(model,device,dataset,optimizer,epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    for i,(x,y) in tqdm(enumerate(dataset)):\n",
    "        x , y  = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        pred = output.max(1,keepdim=True)[1]\n",
    "        correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "        loss = criterion(output,y) \n",
    "        loss.backward()\n",
    "        optimizer.step()   \n",
    "        \n",
    "    train_ac.append(correct/len(data_train))   \n",
    "    train_loss.append(loss.item())\n",
    "    print(\"Epoch {} Loss {:.4f} Accuracy {}/{} ({:.0f}%)\".format(epoch,loss,correct,len(data_train),100*correct/len(data_train)))\n",
    "\n",
    "def vaild(model,device,dataset):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i,(x,y) in tqdm(enumerate(dataset)):\n",
    "            x,y = x.to(device) ,y.to(device)\n",
    "            output = model(x)\n",
    "            loss = criterion(output,y)\n",
    "            pred = output.max(1,keepdim=True)[1]\n",
    "            global  y_pred \n",
    "            y_pred += pred.view(pred.size()[0]).cpu().numpy().tolist()\n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "            \n",
    "    vaild_ac.append(correct/len(data_vaild)) \n",
    "    vaild_loss.append(loss.item())\n",
    "    print(\"Test Loss {:.4f} Accuracy {}/{} ({:.0f}%)\".format(loss,correct,len(data_vaild),100.*correct/len(data_vaild)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RUN():\n",
    "    for epoch in range(1,EPOCH+1):\n",
    "        #尝试动态学习率\n",
    "        train(model,device=DEVICE,dataset=train_set,optimizer=optimizer,epoch=epoch)\n",
    "        vaild(model,device=DEVICE,dataset=vaild_set)\n",
    "        #保存模型\n",
    "    torch.save(model,'./model/model_vgg.pkl')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    RUN()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
